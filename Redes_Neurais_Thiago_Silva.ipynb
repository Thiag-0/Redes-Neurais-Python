{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Thiag-0/Redes-Neurais-Python/blob/main/Redes_Neurais_Thiago_Silva.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOME : THIAGO AUGUSTO DA SILVA LIMA**"
      ],
      "metadata": {
        "id": "fGSfOeGrRNSt"
      },
      "id": "fGSfOeGrRNSt"
    },
    {
      "cell_type": "markdown",
      "id": "8a685f2b",
      "metadata": {
        "id": "8a685f2b"
      },
      "source": [
        "# Lista de Exercícios Práticos - Introdução às Redes Neurais"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "705f6651",
      "metadata": {
        "id": "705f6651"
      },
      "source": [
        "## Exercício 1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98de16f0",
      "metadata": {
        "id": "98de16f0"
      },
      "source": [
        "\n",
        "Implemente uma rede neural simples para resolver um problema de classificação utilizando o **Pima Indians Diabetes Dataset**. Esta base de dados apresenta em registros de exames de pacientes e tem como objetivo diagnosticar se um determinado paciente tem diabetes. Mais detalhes sobre a base: https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database\n",
        "\n",
        "\n",
        "1. Divida o dataset em conjuntos de treino e teste.\n",
        "2. Normalize os dados para o intervalo [0, 1].\n",
        "3. Crie uma rede neural com:\n",
        "   - Uma camada oculta de 16 neurônios e ativação ReLU.\n",
        "   - Uma camada de saída com ativação sigmoide.\n",
        "4. Treine a rede por 50 épocas e avalie sua precisão.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Carregar dataset e preparar os dados\n",
        "data = load_diabetes()\n",
        "X, y = data.data, data.target\n",
        "y = (y > y.mean()).astype(int)  # Classificação binária: acima da média (1) ou abaixo (0)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalização\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Construção da rede neural\n",
        "model = Sequential([\n",
        "    Dense(16, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compilação do modelo\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Treinamento do modelo\n",
        "history = model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=1, validation_split=0.2)\n",
        "\n",
        "# Avaliação do modelo\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Loss no conjunto de teste: {loss:.4f}\")\n",
        "print(f\"Acurácia no conjunto de teste: {accuracy:.4f}\")\n",
        "\n",
        "# Fazer previsões\n",
        "y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
        "final_accuracy = np.mean(y_pred.flatten() == y_test)\n",
        "print(f\"Acurácia calculada manualmente: {final_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Szmd3-OYQ6Vr",
        "outputId": "14cedd25-c969-4fde-8d32-6e2adf141e43"
      },
      "id": "Szmd3-OYQ6Vr",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.3813 - loss: 0.9868 - val_accuracy: 0.3099 - val_loss: 0.9840\n",
            "Epoch 2/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4252 - loss: 0.9098 - val_accuracy: 0.3099 - val_loss: 0.9421\n",
            "Epoch 3/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3905 - loss: 0.9063 - val_accuracy: 0.3099 - val_loss: 0.9045\n",
            "Epoch 4/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3957 - loss: 0.8555 - val_accuracy: 0.3099 - val_loss: 0.8724\n",
            "Epoch 5/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4174 - loss: 0.7991 - val_accuracy: 0.3380 - val_loss: 0.8445\n",
            "Epoch 6/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4428 - loss: 0.7785 - val_accuracy: 0.3380 - val_loss: 0.8200\n",
            "Epoch 7/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4702 - loss: 0.7441 - val_accuracy: 0.3380 - val_loss: 0.7998\n",
            "Epoch 8/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4942 - loss: 0.7231 - val_accuracy: 0.3521 - val_loss: 0.7819\n",
            "Epoch 9/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4414 - loss: 0.7383 - val_accuracy: 0.3803 - val_loss: 0.7656\n",
            "Epoch 10/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5288 - loss: 0.6937 - val_accuracy: 0.4085 - val_loss: 0.7513\n",
            "Epoch 11/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5067 - loss: 0.6939 - val_accuracy: 0.4085 - val_loss: 0.7385\n",
            "Epoch 12/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5880 - loss: 0.6834 - val_accuracy: 0.4366 - val_loss: 0.7275\n",
            "Epoch 13/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5873 - loss: 0.6629 - val_accuracy: 0.4789 - val_loss: 0.7174\n",
            "Epoch 14/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6147 - loss: 0.6538 - val_accuracy: 0.5070 - val_loss: 0.7082\n",
            "Epoch 15/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5829 - loss: 0.6545 - val_accuracy: 0.5352 - val_loss: 0.7000\n",
            "Epoch 16/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6124 - loss: 0.6275 - val_accuracy: 0.5634 - val_loss: 0.6919\n",
            "Epoch 17/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6879 - loss: 0.6193 - val_accuracy: 0.5915 - val_loss: 0.6842\n",
            "Epoch 18/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6614 - loss: 0.6109 - val_accuracy: 0.6338 - val_loss: 0.6770\n",
            "Epoch 19/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7005 - loss: 0.5997 - val_accuracy: 0.6338 - val_loss: 0.6704\n",
            "Epoch 20/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6750 - loss: 0.5944 - val_accuracy: 0.6338 - val_loss: 0.6643\n",
            "Epoch 21/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6881 - loss: 0.6054 - val_accuracy: 0.6479 - val_loss: 0.6583\n",
            "Epoch 22/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6964 - loss: 0.5777 - val_accuracy: 0.6620 - val_loss: 0.6527\n",
            "Epoch 23/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7114 - loss: 0.5684 - val_accuracy: 0.6620 - val_loss: 0.6484\n",
            "Epoch 24/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6968 - loss: 0.5679 - val_accuracy: 0.6761 - val_loss: 0.6441\n",
            "Epoch 25/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7176 - loss: 0.5609 - val_accuracy: 0.6761 - val_loss: 0.6393\n",
            "Epoch 26/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7104 - loss: 0.5795 - val_accuracy: 0.6761 - val_loss: 0.6349\n",
            "Epoch 27/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7247 - loss: 0.5651 - val_accuracy: 0.6761 - val_loss: 0.6326\n",
            "Epoch 28/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7196 - loss: 0.5525 - val_accuracy: 0.6901 - val_loss: 0.6287\n",
            "Epoch 29/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7213 - loss: 0.5510 - val_accuracy: 0.6761 - val_loss: 0.6256\n",
            "Epoch 30/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7638 - loss: 0.5221 - val_accuracy: 0.6761 - val_loss: 0.6226\n",
            "Epoch 31/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7383 - loss: 0.5199 - val_accuracy: 0.6761 - val_loss: 0.6204\n",
            "Epoch 32/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7565 - loss: 0.5294 - val_accuracy: 0.6761 - val_loss: 0.6179\n",
            "Epoch 33/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7393 - loss: 0.5330 - val_accuracy: 0.6761 - val_loss: 0.6152\n",
            "Epoch 34/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7356 - loss: 0.5087 - val_accuracy: 0.6761 - val_loss: 0.6129\n",
            "Epoch 35/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7507 - loss: 0.5224 - val_accuracy: 0.6761 - val_loss: 0.6114\n",
            "Epoch 36/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7574 - loss: 0.5127 - val_accuracy: 0.6761 - val_loss: 0.6097\n",
            "Epoch 37/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7387 - loss: 0.5183 - val_accuracy: 0.6620 - val_loss: 0.6080\n",
            "Epoch 38/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7484 - loss: 0.4988 - val_accuracy: 0.6620 - val_loss: 0.6072\n",
            "Epoch 39/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7463 - loss: 0.5176 - val_accuracy: 0.6620 - val_loss: 0.6052\n",
            "Epoch 40/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7697 - loss: 0.4968 - val_accuracy: 0.6761 - val_loss: 0.6037\n",
            "Epoch 41/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7516 - loss: 0.5096 - val_accuracy: 0.6761 - val_loss: 0.6028\n",
            "Epoch 42/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7337 - loss: 0.5098 - val_accuracy: 0.7042 - val_loss: 0.6019\n",
            "Epoch 43/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7399 - loss: 0.4910 - val_accuracy: 0.7042 - val_loss: 0.6014\n",
            "Epoch 44/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7522 - loss: 0.4798 - val_accuracy: 0.7042 - val_loss: 0.6003\n",
            "Epoch 45/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7635 - loss: 0.4821 - val_accuracy: 0.7042 - val_loss: 0.6002\n",
            "Epoch 46/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7405 - loss: 0.5161 - val_accuracy: 0.6901 - val_loss: 0.5988\n",
            "Epoch 47/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7334 - loss: 0.5009 - val_accuracy: 0.6901 - val_loss: 0.5982\n",
            "Epoch 48/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7191 - loss: 0.4888 - val_accuracy: 0.6901 - val_loss: 0.5980\n",
            "Epoch 49/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7563 - loss: 0.4860 - val_accuracy: 0.6901 - val_loss: 0.5974\n",
            "Epoch 50/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7486 - loss: 0.4872 - val_accuracy: 0.6901 - val_loss: 0.5970\n",
            "Loss no conjunto de teste: 0.5507\n",
            "Acurácia no conjunto de teste: 0.7528\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
            "Acurácia calculada manualmente: 0.7528\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49f26b11",
      "metadata": {
        "id": "49f26b11"
      },
      "source": [
        "## Exercício 2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cba9bfb4",
      "metadata": {
        "id": "cba9bfb4"
      },
      "source": [
        "\n",
        "Treine uma rede neural para reconhecer dígitos escritos à mão usando a base de dados **MNIST**. https://www.kaggle.com/datasets/hojjatk/mnist-dataset\n",
        "\n",
        "1. Carregue e visualize o dataset MNIST.\n",
        "2. Pré-processe os dados (normalize as entradas e transforme os rótulos em *one-hot encoding*).\n",
        "3. Crie uma rede com:\n",
        "   - Entrada: 784 neurônios (28x28 pixels achatados).\n",
        "   - Oculta: 64 neurônios com ativação ReLU.\n",
        "   - Saída: 10 neurônios com ativação softmax.\n",
        "4. Treine a rede por 10 épocas e avalie a acurácia no conjunto de teste.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Carregar o dataset\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Visualizar algumas imagens\n",
        "plt.figure(figsize=(10, 5))\n",
        "for i in range(6):\n",
        "    plt.subplot(2, 3, i + 1)\n",
        "    plt.imshow(X_train[i], cmap='gray')\n",
        "    plt.title(f\"Rótulo: {y_train[i]}\")\n",
        "    plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# Pré-processamento\n",
        "X_train = X_train.reshape(-1, 28 * 28) / 255.0\n",
        "X_test = X_test.reshape(-1, 28 * 28) / 255.0\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# Construção da rede neural\n",
        "model = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(784,)),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compilação do modelo\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Treinamento do modelo\n",
        "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2, verbose=1)\n",
        "\n",
        "# Avaliação do modelo\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Loss no conjunto de teste: {loss:.4f}\")\n",
        "print(f\"Acurácia no conjunto de teste: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 861
        },
        "id": "7ZCyPVDwSzwN",
        "outputId": "25857b8b-251f-49d7-dde0-b3d4ce68b6f5"
      },
      "id": "7ZCyPVDwSzwN",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 6 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8447 - loss: 0.5549 - val_accuracy: 0.9449 - val_loss: 0.1969\n",
            "Epoch 2/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9470 - loss: 0.1833 - val_accuracy: 0.9583 - val_loss: 0.1438\n",
            "Epoch 3/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9600 - loss: 0.1323 - val_accuracy: 0.9633 - val_loss: 0.1252\n",
            "Epoch 4/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9693 - loss: 0.1034 - val_accuracy: 0.9667 - val_loss: 0.1145\n",
            "Epoch 5/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9769 - loss: 0.0785 - val_accuracy: 0.9668 - val_loss: 0.1095\n",
            "Epoch 6/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9813 - loss: 0.0653 - val_accuracy: 0.9714 - val_loss: 0.1009\n",
            "Epoch 7/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9835 - loss: 0.0550 - val_accuracy: 0.9707 - val_loss: 0.1031\n",
            "Epoch 8/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9868 - loss: 0.0474 - val_accuracy: 0.9729 - val_loss: 0.0961\n",
            "Epoch 9/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9885 - loss: 0.0376 - val_accuracy: 0.9728 - val_loss: 0.0973\n",
            "Epoch 10/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9910 - loss: 0.0318 - val_accuracy: 0.9727 - val_loss: 0.1022\n",
            "Loss no conjunto de teste: 0.0883\n",
            "Acurácia no conjunto de teste: 0.9731\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "127bdef8",
      "metadata": {
        "id": "127bdef8"
      },
      "source": [
        "## Exercício 3"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15718153",
      "metadata": {
        "id": "15718153"
      },
      "source": [
        "\n",
        "Implemente uma rede neural para prever valores contínuos utilizando o **Boston Housing Dataset**. https://www.kaggle.com/code/prasadperera/the-boston-housing-dataset\n",
        "\n",
        "1. Carregue o dataset Boston Housing.\n",
        "2. Normalize os dados de entrada.\n",
        "3. Crie uma rede com:\n",
        "   - Camada de entrada: 13 neurônios.\n",
        "   - Camada oculta: 32 neurônios com ativação ReLU.\n",
        "   - Camada de saída: 1 neurônio.\n",
        "4. Treine o modelo e avalie o erro quadrático médio (MSE) no conjunto de teste.\n",
        "\n",
        "Dica: a biblioteca sci-kit learn possui um módulo de métricas de erro. Dentre as disponíveis, está o MSE. https://scikit-learn.org/1.5/modules/generated/sklearn.metrics.mean_squared_error.html\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import boston_housing\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Carregar o dataset\n",
        "(X_train, y_train), (X_test, y_test) = boston_housing.load_data()\n",
        "\n",
        "# Normalização\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Construção da rede neural\n",
        "model = Sequential([\n",
        "    Dense(32, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    Dense(1)  # Saída com um neurônio para prever valores contínuos\n",
        "])\n",
        "\n",
        "# Compilação do modelo\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
        "\n",
        "# Treinamento do modelo\n",
        "history = model.fit(X_train, y_train, epochs=50, batch_size=16, validation_split=0.2, verbose=1)\n",
        "\n",
        "# Avaliação do modelo\n",
        "loss, mse = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Loss no conjunto de teste: {loss:.4f}\")\n",
        "print(f\"MSE no conjunto de teste: {mse:.4f}\")\n",
        "\n",
        "# Previsões e cálculo do MSE\n",
        "y_pred = model.predict(X_test)\n",
        "mse_manual = mean_squared_error(y_test, y_pred)\n",
        "print(f\"MSE calculado manualmente: {mse_manual:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GONvyQGTupI",
        "outputId": "c705b733-9229-49a9-e547-e0af5858def0"
      },
      "id": "1GONvyQGTupI",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
            "\u001b[1m57026/57026\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 590.6953 - mse: 590.6953 - val_loss: 619.7592 - val_mse: 619.7592\n",
            "Epoch 2/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 553.0490 - mse: 553.0490 - val_loss: 594.3633 - val_mse: 594.3633\n",
            "Epoch 3/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 501.2275 - mse: 501.2275 - val_loss: 567.4942 - val_mse: 567.4942\n",
            "Epoch 4/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 533.9467 - mse: 533.9467 - val_loss: 539.9077 - val_mse: 539.9077\n",
            "Epoch 5/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 461.4696 - mse: 461.4696 - val_loss: 510.3145 - val_mse: 510.3145\n",
            "Epoch 6/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 449.1105 - mse: 449.1105 - val_loss: 479.3032 - val_mse: 479.3032\n",
            "Epoch 7/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 404.6401 - mse: 404.6401 - val_loss: 446.0641 - val_mse: 446.0641\n",
            "Epoch 8/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 403.9621 - mse: 403.9621 - val_loss: 411.0808 - val_mse: 411.0808\n",
            "Epoch 9/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 347.1220 - mse: 347.1220 - val_loss: 376.9491 - val_mse: 376.9491\n",
            "Epoch 10/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 330.8731 - mse: 330.8731 - val_loss: 342.0906 - val_mse: 342.0906\n",
            "Epoch 11/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 296.6602 - mse: 296.6602 - val_loss: 308.4906 - val_mse: 308.4906\n",
            "Epoch 12/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 231.8932 - mse: 231.8932 - val_loss: 277.1242 - val_mse: 277.1242\n",
            "Epoch 13/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 219.4176 - mse: 219.4176 - val_loss: 247.0117 - val_mse: 247.0117\n",
            "Epoch 14/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 167.2216 - mse: 167.2216 - val_loss: 220.3954 - val_mse: 220.3954\n",
            "Epoch 15/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 163.2529 - mse: 163.2529 - val_loss: 196.5876 - val_mse: 196.5876\n",
            "Epoch 16/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 161.8858 - mse: 161.8858 - val_loss: 175.6891 - val_mse: 175.6891\n",
            "Epoch 17/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 132.7216 - mse: 132.7216 - val_loss: 158.7770 - val_mse: 158.7770\n",
            "Epoch 18/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 122.6948 - mse: 122.6948 - val_loss: 143.6139 - val_mse: 143.6139\n",
            "Epoch 19/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 88.8275 - mse: 88.8275 - val_loss: 131.2522 - val_mse: 131.2522\n",
            "Epoch 20/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 97.1286 - mse: 97.1286 - val_loss: 119.8269 - val_mse: 119.8269\n",
            "Epoch 21/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 82.0166 - mse: 82.0166 - val_loss: 110.6721 - val_mse: 110.6721\n",
            "Epoch 22/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 79.6393 - mse: 79.6393 - val_loss: 102.2809 - val_mse: 102.2809\n",
            "Epoch 23/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 74.1917 - mse: 74.1917 - val_loss: 95.5639 - val_mse: 95.5639\n",
            "Epoch 24/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 67.2797 - mse: 67.2797 - val_loss: 88.7926 - val_mse: 88.7926\n",
            "Epoch 25/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 62.9716 - mse: 62.9716 - val_loss: 83.1695 - val_mse: 83.1695\n",
            "Epoch 26/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 46.6662 - mse: 46.6662 - val_loss: 78.1934 - val_mse: 78.1934\n",
            "Epoch 27/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 39.0572 - mse: 39.0572 - val_loss: 73.9529 - val_mse: 73.9529\n",
            "Epoch 28/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 45.8360 - mse: 45.8360 - val_loss: 69.5788 - val_mse: 69.5788\n",
            "Epoch 29/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 50.7523 - mse: 50.7523 - val_loss: 65.7114 - val_mse: 65.7114\n",
            "Epoch 30/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 38.6301 - mse: 38.6301 - val_loss: 62.6057 - val_mse: 62.6057\n",
            "Epoch 31/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 41.7500 - mse: 41.7500 - val_loss: 59.6871 - val_mse: 59.6871\n",
            "Epoch 32/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 49.9362 - mse: 49.9362 - val_loss: 57.1328 - val_mse: 57.1328\n",
            "Epoch 33/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 35.7129 - mse: 35.7129 - val_loss: 54.9028 - val_mse: 54.9028\n",
            "Epoch 34/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 31.9877 - mse: 31.9877 - val_loss: 52.8991 - val_mse: 52.8991\n",
            "Epoch 35/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 36.9595 - mse: 36.9595 - val_loss: 50.9723 - val_mse: 50.9723\n",
            "Epoch 36/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 35.1877 - mse: 35.1877 - val_loss: 49.1832 - val_mse: 49.1832\n",
            "Epoch 37/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 30.6454 - mse: 30.6454 - val_loss: 47.7758 - val_mse: 47.7758\n",
            "Epoch 38/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 33.9751 - mse: 33.9751 - val_loss: 46.1716 - val_mse: 46.1716\n",
            "Epoch 39/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 24.7591 - mse: 24.7591 - val_loss: 44.9233 - val_mse: 44.9233\n",
            "Epoch 40/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 31.6310 - mse: 31.6310 - val_loss: 43.5819 - val_mse: 43.5819\n",
            "Epoch 41/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 36.6759 - mse: 36.6759 - val_loss: 42.8388 - val_mse: 42.8388\n",
            "Epoch 42/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 30.5591 - mse: 30.5591 - val_loss: 41.9864 - val_mse: 41.9864\n",
            "Epoch 43/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 33.4897 - mse: 33.4897 - val_loss: 41.1439 - val_mse: 41.1439\n",
            "Epoch 44/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 23.7276 - mse: 23.7276 - val_loss: 40.3572 - val_mse: 40.3572\n",
            "Epoch 45/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 29.3889 - mse: 29.3889 - val_loss: 39.6773 - val_mse: 39.6773\n",
            "Epoch 46/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 29.3577 - mse: 29.3577 - val_loss: 39.0571 - val_mse: 39.0571\n",
            "Epoch 47/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 24.1665 - mse: 24.1665 - val_loss: 38.5153 - val_mse: 38.5153\n",
            "Epoch 48/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 21.6432 - mse: 21.6432 - val_loss: 37.9217 - val_mse: 37.9217\n",
            "Epoch 49/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 26.9993 - mse: 26.9993 - val_loss: 37.4611 - val_mse: 37.4611\n",
            "Epoch 50/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 29.3580 - mse: 29.3580 - val_loss: 36.7165 - val_mse: 36.7165\n",
            "Loss no conjunto de teste: 33.1530\n",
            "MSE no conjunto de teste: 33.1530\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 9 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7ea727e789d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r\u001b[1m1/4\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 12 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7ea727e789d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
            "MSE calculado manualmente: 33.1530\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}